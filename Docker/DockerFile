# Use a base image with Java 11
FROM openjdk:11-jdk-slim

# Install Python 3.9.6
RUN apt-get update && \
    apt-get install -y wget build-essential zlib1g-dev libssl-dev libncurses-dev libffi-dev libsqlite3-dev && \
    wget https://www.python.org/ftp/python/3.9.6/Python-3.9.6.tgz && \
    tar xzf Python-3.9.6.tgz && \
    cd Python-3.9.6 && \
    ./configure --enable-optimizations && \
    make altinstall && \
    cd .. && \
    rm -rf Python-3.9.6 Python-3.9.6.tgz

# Install Apache Spark
ENV SPARK_VERSION=3.5.5
ENV HADOOP_VERSION=3
RUN wget https://downloads.apache.org/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz && \
    tar xzf spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz -C /opt && \
    rm spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz
ENV SPARK_HOME=/opt/spark-3.5.5-bin-hadoop3
ENV PATH=$SPARK_HOME/bin:$PATH

# Verify Spark installation
RUN ls -l $SPARK_HOME/bin

# Set the working directory
WORKDIR /opt/bitnami/spark

# Copy jobs directory
COPY ./jobs /opt/bitnami/spark/jobs
